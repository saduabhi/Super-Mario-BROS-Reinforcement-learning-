{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5361184f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu\n",
      "  Downloading tensorflow_gpu-2.8.0-cp38-cp38-win_amd64.whl (438.0 MB)\n",
      "Collecting keras<2.9,>=2.8.0rc0\n",
      "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Collecting absl-py>=0.4.0\n",
      "  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Collecting libclang>=9.0.1\n",
      "  Downloading libclang-14.0.1-py2.py3-none-win_amd64.whl (14.2 MB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.20.1)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (52.0.0.post20210125)\n",
      "Collecting flatbuffers>=1.12\n",
      "  Downloading flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (2.10.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.15.0)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting gast>=0.2.1\n",
      "  Downloading gast-0.5.3-py3-none-any.whl (19 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.12.1)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.20.1-cp38-cp38-win_amd64.whl (904 kB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.25.0-cp38-cp38-win_amd64.whl (1.5 MB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
      "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.46.1-cp38-cp38-win_amd64.whl (3.5 MB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting tensorboard<2.9,>=2.8\n",
      "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (3.7.4.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-gpu) (0.36.2)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.6.6-py2.py3-none-any.whl (156 kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (1.0.1)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (2.25.1)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.0.0-py3-none-any.whl (9.1 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Downloading importlib_metadata-4.11.3-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow-gpu) (3.4.1)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu) (1.26.4)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=ff4c95812be9976289ece18f985641b66c39bb239d3b3a52e4978b9824138555\n",
      "  Stored in directory: c:\\users\\computing\\appdata\\local\\pip\\cache\\wheels\\a0\\16\\9c\\5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built termcolor\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tf-estimator-nightly, termcolor, tensorflow-io-gcs-filesystem, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow-gpu\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 3.10.0\n",
      "    Uninstalling importlib-metadata-3.10.0:\n",
      "      Successfully uninstalled importlib-metadata-3.10.0\n",
      "Successfully installed absl-py-1.0.0 astunparse-1.6.3 cachetools-5.0.0 flatbuffers-2.0 gast-0.5.3 google-auth-2.6.6 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.46.1 importlib-metadata-4.11.3 keras-2.8.0 keras-preprocessing-1.1.2 libclang-14.0.1 markdown-3.3.7 oauthlib-3.2.0 opt-einsum-3.3.0 protobuf-3.20.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.8 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-gpu-2.8.0 tensorflow-io-gcs-filesystem-0.25.0 termcolor-1.1.0 tf-estimator-nightly-2.8.0.dev2021122109\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e018f0",
   "metadata": {},
   "source": [
    "**Installing the game**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73aa6aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gym_super_mario_bros==7.3.0\n",
      "  Downloading gym_super_mario_bros-7.3.0-py2.py3-none-any.whl (198 kB)\n",
      "Collecting nes_py\n",
      "  Downloading nes_py-8.1.8.tar.gz (76 kB)\n",
      "Collecting gym>=0.17.2\n",
      "  Downloading gym-0.23.1.tar.gz (626 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from nes_py) (1.20.1)\n",
      "Collecting pyglet<=1.5.11,>=1.4.0\n",
      "  Downloading pyglet-1.5.11-py3-none-any.whl (1.1 MB)\n",
      "Requirement already satisfied: tqdm>=4.48.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from nes_py) (4.59.0)\n",
      "Collecting gym-notices>=0.0.4\n",
      "  Downloading gym_notices-0.0.6-py3-none-any.whl (2.7 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.10.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gym>=0.17.2->nes_py) (4.11.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gym>=0.17.2->nes_py) (1.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.10.0->gym>=0.17.2->nes_py) (3.4.1)\n",
      "Building wheels for collected packages: nes-py, gym\n",
      "  Building wheel for nes-py (setup.py): started\n",
      "  Building wheel for nes-py (setup.py): finished with status 'done'\n",
      "  Created wheel for nes-py: filename=nes_py-8.1.8-cp38-cp38-win_amd64.whl size=48003 sha256=6cb8e7577c793830dcd48be0b7c511e12e6049c797f086c74b8caf9d88bac8b6\n",
      "  Stored in directory: c:\\users\\computing\\appdata\\local\\pip\\cache\\wheels\\8d\\6e\\f0\\113c979eba40def28ee9b3c81a4adec00386106d81fb3bc2c2\n",
      "  Building wheel for gym (PEP 517): started\n",
      "  Building wheel for gym (PEP 517): finished with status 'done'\n",
      "  Created wheel for gym: filename=gym-0.23.1-py3-none-any.whl size=701356 sha256=bc145f757ac30f1c35e0ae53e0b8c861715f0fdfde8e3f52a3b255e3cc9c80af\n",
      "  Stored in directory: c:\\users\\computing\\appdata\\local\\pip\\cache\\wheels\\78\\28\\77\\b0c74e80a2a4faae0161d5c53bc4f8e436e77aedc79136ee13\n",
      "Successfully built nes-py gym\n",
      "Installing collected packages: gym-notices, pyglet, gym, nes-py, gym-super-mario-bros\n",
      "Successfully installed gym-0.23.1 gym-notices-0.0.6 gym-super-mario-bros-7.3.0 nes-py-8.1.8 pyglet-1.5.11\n"
     ]
    }
   ],
   "source": [
    "!pip install gym_super_mario_bros==7.3.0 nes_py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7496b59b",
   "metadata": {},
   "source": [
    "**Importing the libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bbe586e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the game\n",
    "import gym_super_mario_bros\n",
    "# Importing the Joypad wrapper\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "# Importing the SIMPLIFIED controls\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f78a3fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from torchvision import transforms\n",
    "import gym\n",
    "from gym.spaces import Box\n",
    "import gym_super_mario_bros\n",
    "import numpy as np\n",
    "import torch\n",
    "from gym.wrappers import FrameStack\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "from torch import nn\n",
    "from torch.distributions import Categorical\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c352577",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "class SkipFrame(gym.Wrapper):\n",
    "    def __init__(self, env, skip):\n",
    "        super().__init__(env)\n",
    "        self._skip = skip\n",
    "\n",
    "    def step(self, action):\n",
    "        total_reward = 0.0\n",
    "        done = False\n",
    "        for i in range(self._skip):\n",
    "            obs, reward, done, info = self.env.step(action)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        return obs, total_reward, done, info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e486e656",
   "metadata": {},
   "source": [
    "**Grayscaling for observation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14813e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrayScaleObservation(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.observation_space = Box(low=0, high=255, shape=self.observation_space.shape[:2], dtype=np.uint8)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        transform = transforms.Grayscale()\n",
    "        return transform(torch.tensor(np.transpose(observation, (2, 0, 1)).copy(), dtype=torch.float))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776d2f5d",
   "metadata": {},
   "source": [
    "**Resizing the observation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abcfff7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gym\\envs\\registration.py:505: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3` with the environment ID `SuperMarioBros-1-1-v3`.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "class ResizeObservation(gym.ObservationWrapper):\n",
    "    def __init__(self, env, shape):\n",
    "        super().__init__(env)\n",
    "        self.shape = (shape, shape)\n",
    "        obs_shape = self.shape + self.observation_space.shape[2:]\n",
    "        self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        transformations = transforms.Compose([transforms.Resize(self.shape), transforms.Normalize(0, 255)])\n",
    "        return transformations(observation).squeeze(0)\n",
    "\n",
    "\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-1-1-v0')\n",
    "env = JoypadSpace(env, [[\"right\"], [\"right\", \"A\"]])\n",
    "env = FrameStack(ResizeObservation(GrayScaleObservation(SkipFrame(env, skip=4)), shape=84), num_stack=4)\n",
    "env.seed(128)\n",
    "env.action_space.seed(128)\n",
    "torch.manual_seed(128)\n",
    "torch.random.manual_seed(128)\n",
    "np.random.seed(128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0882fbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=4, out_channels=32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3136, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, env.action_space.n)\n",
    "        )\n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=4, out_channels=32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3136, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, obs):\n",
    "        return Categorical(logits=self.actor(obs)), self.critic(obs).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8df6079f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPOSolver:\n",
    "    def __init__(self):\n",
    "        self.rewards = []\n",
    "        self.gamma = 0.95\n",
    "        self.lamda = 0.95\n",
    "        self.worker_steps = 4096\n",
    "        self.n_mini_batch = 4\n",
    "        self.epochs = 30\n",
    "        self.save_directory = r\"C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\"\n",
    "        self.batch_size = self.worker_steps\n",
    "        self.mini_batch_size = self.batch_size // self.n_mini_batch\n",
    "        self.obs = env.reset().__array__()\n",
    "        self.policy = Model().to(device)\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        self.optimizer = torch.optim.Adam([\n",
    "            {'params': self.policy.actor.parameters(), 'lr': 0.00025},\n",
    "            {'params': self.policy.critic.parameters(), 'lr': 0.001}\n",
    "        ], eps=1e-4)\n",
    "        self.policy_old = Model().to(device)\n",
    "        self.policy_old.load_state_dict(self.policy.state_dict())\n",
    "        self.all_episode_rewards = []\n",
    "        self.all_mean_rewards = []\n",
    "        self.episode = 0\n",
    "\n",
    "    def save_checkpoint(self):\n",
    "        filename = os.path.join(self.save_directory, 'checkpoint_{}.pth'.format(self.episode))\n",
    "        torch.save(self.policy_old.state_dict(), f=filename)\n",
    "        print('Checkpoint saved to \\'{}\\''.format(filename))\n",
    "\n",
    "    def load_checkpoint(self, filename):\n",
    "        self.policy.load_state_dict(torch.load(os.path.join(self.save_directory, filename)))\n",
    "        self.policy_old.load_state_dict(torch.load(os.path.join(self.save_directory, filename)))\n",
    "        print('Resuming training from checkpoint \\'{}\\'.'.format(filename))\n",
    "\n",
    "    def sample(self):\n",
    "        rewards = np.zeros(self.worker_steps, dtype=np.float32)\n",
    "        actions = np.zeros(self.worker_steps, dtype=np.int32)\n",
    "        done = np.zeros(self.worker_steps, dtype=bool)\n",
    "        obs = np.zeros((self.worker_steps, 4, 84, 84), dtype=np.float32)\n",
    "        log_pis = np.zeros(self.worker_steps, dtype=np.float32)\n",
    "        values = np.zeros(self.worker_steps, dtype=np.float32)\n",
    "        for t in range(self.worker_steps):\n",
    "            with torch.no_grad():\n",
    "                obs[t] = self.obs\n",
    "                pi, v = self.policy_old(torch.tensor(self.obs, dtype=torch.float32, device=device).unsqueeze(0))\n",
    "                values[t] = v.cpu().numpy()\n",
    "                a = pi.sample()\n",
    "                actions[t] = a.cpu().numpy()\n",
    "                log_pis[t] = pi.log_prob(a).cpu().numpy()\n",
    "            self.obs, rewards[t], done[t], _ = env.step(actions[t])\n",
    "            self.obs = self.obs.__array__()\n",
    "            env.render()\n",
    "            self.rewards.append(rewards[t])\n",
    "            if done[t]:\n",
    "                self.episode += 1\n",
    "                self.all_episode_rewards.append(np.sum(self.rewards))\n",
    "                self.rewards = []\n",
    "                env.reset()\n",
    "                if self.episode % 10 == 0:\n",
    "                    print('Episode: {}, average reward: {}'.format(self.episode, np.mean(self.all_episode_rewards[-10:])))\n",
    "                    self.all_mean_rewards.append(np.mean(self.all_episode_rewards[-10:]))\n",
    "                    plt.plot(self.all_mean_rewards)\n",
    "                    plt.savefig(\"{}/mean_reward_{}.png\".format(self.save_directory, self.episode))\n",
    "                    plt.clf()\n",
    "                    self.save_checkpoint()\n",
    "        returns, advantages = self.calculate_advantages(done, rewards, values)\n",
    "        return {\n",
    "            'obs': torch.tensor(obs.reshape(obs.shape[0], *obs.shape[1:]), dtype=torch.float32, device=device),\n",
    "            'actions': torch.tensor(actions, device=device),\n",
    "            'values': torch.tensor(values, device=device),\n",
    "            'log_pis': torch.tensor(log_pis, device=device),\n",
    "            'advantages': torch.tensor(advantages, device=device, dtype=torch.float32),\n",
    "            'returns': torch.tensor(returns, device=device, dtype=torch.float32)\n",
    "        }\n",
    "\n",
    "    def calculate_advantages(self, done, rewards, values):\n",
    "        _, last_value = self.policy_old(torch.tensor(self.obs, dtype=torch.float32, device=device).unsqueeze(0))\n",
    "        last_value = last_value.cpu().data.numpy()\n",
    "        values = np.append(values, last_value)\n",
    "        returns = []\n",
    "        gae = 0\n",
    "        for i in reversed(range(len(rewards))):\n",
    "            mask = 1.0 - done[i]\n",
    "            delta = rewards[i] + self.gamma * values[i + 1] * mask - values[i]\n",
    "            gae = delta + self.gamma * self.lamda * mask * gae\n",
    "            returns.insert(0, gae + values[i])\n",
    "        adv = np.array(returns) - values[:-1]\n",
    "        return returns, (adv - np.mean(adv)) / (np.std(adv) + 1e-8)\n",
    "\n",
    "    def train(self, samples, clip_range):\n",
    "        indexes = torch.randperm(self.batch_size)\n",
    "        for start in range(0, self.batch_size, self.mini_batch_size):\n",
    "            end = start + self.mini_batch_size\n",
    "            mini_batch_indexes = indexes[start: end]\n",
    "            mini_batch = {}\n",
    "            for k, v in samples.items():\n",
    "                mini_batch[k] = v[mini_batch_indexes]\n",
    "            for _ in range(self.epochs):\n",
    "                loss = self.calculate_loss(clip_range=clip_range, samples=mini_batch)\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "            self.policy_old.load_state_dict(self.policy.state_dict())\n",
    "\n",
    "    def calculate_loss(self, samples, clip_range):\n",
    "        sampled_returns = samples['returns']\n",
    "        sampled_advantages = samples['advantages']\n",
    "        pi, value = self.policy(samples['obs'])\n",
    "        ratio = torch.exp(pi.log_prob(samples['actions']) - samples['log_pis'])\n",
    "        clipped_ratio = ratio.clamp(min=1.0 - clip_range, max=1.0 + clip_range)\n",
    "        policy_reward = torch.min(ratio * sampled_advantages, clipped_ratio * sampled_advantages)\n",
    "        entropy_bonus = pi.entropy()\n",
    "        vf_loss = self.mse_loss(value, sampled_returns)\n",
    "        loss = -policy_reward + 0.5 * vf_loss - 0.01 * entropy_bonus\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5910c62f",
   "metadata": {},
   "source": [
    "**Using PPO agent as solver**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c05317a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gym_super_mario_bros\\smb_env.py:148: RuntimeWarning: overflow encountered in ubyte_scalars\n",
      "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 10, average reward: 660.5\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_10.pth'\n",
      "Episode: 20, average reward: 606.4000244140625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_20.pth'\n",
      "Episode: 30, average reward: 723.4000244140625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_30.pth'\n",
      "Episode: 40, average reward: 666.5\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_40.pth'\n",
      "Episode: 50, average reward: 495.5\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_50.pth'\n",
      "Episode: 60, average reward: 723.7999877929688\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_60.pth'\n",
      "Episode: 70, average reward: 645.2000122070312\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_70.pth'\n",
      "Episode: 80, average reward: 695.2999877929688\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_80.pth'\n",
      "Episode: 90, average reward: 800.4000244140625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_90.pth'\n",
      "Episode: 100, average reward: 847.2999877929688\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_100.pth'\n",
      "Episode: 110, average reward: 779.2999877929688\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_110.pth'\n",
      "Episode: 120, average reward: 716.5\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_120.pth'\n",
      "Episode: 130, average reward: 503.79998779296875\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_130.pth'\n",
      "Episode: 140, average reward: 667.7999877929688\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_140.pth'\n",
      "Episode: 150, average reward: 907.2000122070312\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_150.pth'\n",
      "Episode: 160, average reward: 741.7000122070312\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_160.pth'\n",
      "Episode: 170, average reward: 1029.800048828125\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_170.pth'\n",
      "Episode: 180, average reward: 690.2000122070312\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_180.pth'\n",
      "Episode: 190, average reward: 689.9000244140625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_190.pth'\n",
      "Episode: 200, average reward: 771.2999877929688\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_200.pth'\n",
      "Episode: 210, average reward: 1044.800048828125\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_210.pth'\n",
      "Episode: 220, average reward: 600.0999755859375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_220.pth'\n",
      "Episode: 230, average reward: 638.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_230.pth'\n",
      "Episode: 240, average reward: 625.5999755859375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_240.pth'\n",
      "Episode: 250, average reward: 800.9000244140625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_250.pth'\n",
      "Episode: 260, average reward: 700.7000122070312\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_260.pth'\n",
      "Episode: 270, average reward: 735.2000122070312\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_270.pth'\n",
      "Episode: 280, average reward: 961.4000244140625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_280.pth'\n",
      "Episode: 290, average reward: 842.4000244140625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_290.pth'\n",
      "Episode: 300, average reward: 567.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_300.pth'\n",
      "Episode: 310, average reward: 716.0999755859375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_310.pth'\n",
      "Episode: 320, average reward: 674.4000244140625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_320.pth'\n",
      "Episode: 330, average reward: 579.2000122070312\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_330.pth'\n",
      "Episode: 340, average reward: 692.7000122070312\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_340.pth'\n",
      "Episode: 350, average reward: 854.5\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_350.pth'\n",
      "Episode: 360, average reward: 1063.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_360.pth'\n",
      "Episode: 370, average reward: 733.7000122070312\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_370.pth'\n",
      "Episode: 380, average reward: 673.7000122070312\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_380.pth'\n",
      "Episode: 390, average reward: 820.5\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_390.pth'\n",
      "Episode: 400, average reward: 960.7000122070312\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_400.pth'\n",
      "Episode: 410, average reward: 527.4000244140625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_410.pth'\n",
      "Episode: 420, average reward: 745.2999877929688\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_420.pth'\n",
      "Episode: 430, average reward: 723.2999877929688\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_430.pth'\n",
      "Episode: 440, average reward: 884.9000244140625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_440.pth'\n",
      "Episode: 450, average reward: 727.7000122070312\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_450.pth'\n",
      "Episode: 460, average reward: 748.2000122070312\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_460.pth'\n",
      "Episode: 470, average reward: 848.9000244140625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_470.pth'\n",
      "Episode: 480, average reward: 764.9000244140625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_480.pth'\n",
      "Episode: 490, average reward: 864.7000122070312\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_490.pth'\n",
      "Episode: 500, average reward: 952.0999755859375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_500.pth'\n",
      "Episode: 510, average reward: 760.4000244140625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_510.pth'\n",
      "Episode: 520, average reward: 705.4000244140625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_520.pth'\n",
      "Episode: 530, average reward: 847.0999755859375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_530.pth'\n",
      "Episode: 540, average reward: 786.9000244140625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_540.pth'\n",
      "Episode: 550, average reward: 835.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_550.pth'\n",
      "Episode: 560, average reward: 838.7999877929688\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_560.pth'\n",
      "Episode: 570, average reward: 945.5999755859375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_570.pth'\n",
      "Episode: 580, average reward: 1052.199951171875\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_580.pth'\n",
      "Episode: 590, average reward: 923.7000122070312\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_590.pth'\n",
      "Episode: 600, average reward: 605.2000122070312\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_600.pth'\n",
      "Episode: 610, average reward: 705.5\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_610.pth'\n",
      "Episode: 620, average reward: 750.9000244140625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_620.pth'\n",
      "Episode: 630, average reward: 859.9000244140625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_630.pth'\n",
      "Episode: 640, average reward: 1108.4000244140625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_640.pth'\n",
      "Episode: 650, average reward: 987.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_650.pth'\n",
      "Episode: 660, average reward: 977.5999755859375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_660.pth'\n",
      "Episode: 670, average reward: 858.7000122070312\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_670.pth'\n",
      "Episode: 680, average reward: 898.5999755859375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_680.pth'\n",
      "Episode: 690, average reward: 891.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_690.pth'\n",
      "Episode: 700, average reward: 800.5999755859375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_700.pth'\n",
      "Episode: 710, average reward: 1015.0999755859375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_710.pth'\n",
      "Episode: 720, average reward: 797.0999755859375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_720.pth'\n",
      "Episode: 730, average reward: 906.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_730.pth'\n",
      "Episode: 740, average reward: 1081.5\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_740.pth'\n",
      "Episode: 750, average reward: 859.2000122070312\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_750.pth'\n",
      "Episode: 760, average reward: 1091.5999755859375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_760.pth'\n",
      "Episode: 770, average reward: 964.0999755859375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_770.pth'\n",
      "Episode: 780, average reward: 1172.0999755859375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_780.pth'\n",
      "Episode: 790, average reward: 1152.5999755859375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_790.pth'\n",
      "Episode: 800, average reward: 934.4000244140625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_800.pth'\n",
      "Episode: 810, average reward: 996.2000122070312\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_810.pth'\n",
      "Episode: 820, average reward: 918.5999755859375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_820.pth'\n",
      "Episode: 830, average reward: 975.7000122070312\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_830.pth'\n",
      "Episode: 840, average reward: 911.4000244140625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_840.pth'\n",
      "Episode: 850, average reward: 1140.199951171875\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_850.pth'\n",
      "Episode: 860, average reward: 1150.300048828125\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_860.pth'\n",
      "Episode: 870, average reward: 1061.199951171875\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_870.pth'\n",
      "Episode: 880, average reward: 1212.5\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_880.pth'\n",
      "Episode: 890, average reward: 991.2000122070312\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_890.pth'\n",
      "Episode: 900, average reward: 1184.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_900.pth'\n",
      "Episode: 910, average reward: 1054.0999755859375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_910.pth'\n",
      "Episode: 920, average reward: 1068.9000244140625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_920.pth'\n",
      "Episode: 930, average reward: 1138.800048828125\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_930.pth'\n",
      "Episode: 940, average reward: 1147.800048828125\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_940.pth'\n",
      "Episode: 950, average reward: 1304.800048828125\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_950.pth'\n",
      "Episode: 960, average reward: 1266.5\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_960.pth'\n",
      "Episode: 970, average reward: 1239.699951171875\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_970.pth'\n",
      "Episode: 980, average reward: 1266.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_980.pth'\n",
      "Episode: 990, average reward: 1308.5\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_990.pth'\n",
      "Episode: 1000, average reward: 1307.699951171875\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1000.pth'\n",
      "Episode: 1010, average reward: 1352.699951171875\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1010.pth'\n",
      "Episode: 1020, average reward: 1428.300048828125\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1020.pth'\n",
      "Episode: 1030, average reward: 1565.800048828125\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1030.pth'\n",
      "Episode: 1040, average reward: 1675.5999755859375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1040.pth'\n",
      "Episode: 1050, average reward: 1574.0999755859375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1050.pth'\n",
      "Episode: 1060, average reward: 1661.800048828125\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1060.pth'\n",
      "Episode: 1070, average reward: 1849.5999755859375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1070.pth'\n",
      "Episode: 1080, average reward: 1753.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1080.pth'\n",
      "Episode: 1090, average reward: 1419.4000244140625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1090.pth'\n",
      "Episode: 1100, average reward: 1273.699951171875\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1100.pth'\n",
      "Episode: 1110, average reward: 1724.5999755859375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1110.pth'\n",
      "Episode: 1120, average reward: 1767.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1120.pth'\n",
      "Episode: 1130, average reward: 1913.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1130.pth'\n",
      "Episode: 1140, average reward: 1871.199951171875\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1140.pth'\n",
      "Episode: 1150, average reward: 2013.9000244140625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1150.pth'\n",
      "Episode: 1160, average reward: 2268.89990234375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1160.pth'\n",
      "Episode: 1170, average reward: 2217.300048828125\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1170.pth'\n",
      "Episode: 1180, average reward: 2406.10009765625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1180.pth'\n",
      "Episode: 1190, average reward: 2202.89990234375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1190.pth'\n",
      "Episode: 1200, average reward: 2197.199951171875\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1200.pth'\n",
      "Episode: 1210, average reward: 2105.10009765625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1210.pth'\n",
      "Episode: 1220, average reward: 1707.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1220.pth'\n",
      "Episode: 1230, average reward: 1803.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1230.pth'\n",
      "Episode: 1240, average reward: 1671.800048828125\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1240.pth'\n",
      "Episode: 1250, average reward: 1776.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1250.pth'\n",
      "Episode: 1260, average reward: 1333.300048828125\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1260.pth'\n",
      "Episode: 1270, average reward: 1704.5\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1270.pth'\n",
      "Episode: 1280, average reward: 1340.5\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1280.pth'\n",
      "Episode: 1290, average reward: 1859.300048828125\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1290.pth'\n",
      "Episode: 1300, average reward: 1764.699951171875\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1300.pth'\n",
      "Episode: 1310, average reward: 2041.0999755859375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1310.pth'\n",
      "Episode: 1320, average reward: 1796.699951171875\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1320.pth'\n",
      "Episode: 1330, average reward: 1957.9000244140625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1330.pth'\n",
      "Episode: 1340, average reward: 1925.199951171875\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1340.pth'\n",
      "Episode: 1350, average reward: 1694.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1350.pth'\n",
      "Episode: 1360, average reward: 1739.199951171875\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1360.pth'\n",
      "Episode: 1370, average reward: 1766.9000244140625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1370.pth'\n",
      "Episode: 1380, average reward: 2169.39990234375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1380.pth'\n",
      "Episode: 1390, average reward: 2326.60009765625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1390.pth'\n",
      "Episode: 1400, average reward: 2366.60009765625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1400.pth'\n",
      "Episode: 1410, average reward: 2211.89990234375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1410.pth'\n",
      "Episode: 1420, average reward: 2599.699951171875\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1420.pth'\n",
      "Episode: 1430, average reward: 2892.89990234375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1430.pth'\n",
      "Episode: 1440, average reward: 1788.300048828125\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1440.pth'\n",
      "Episode: 1450, average reward: 2892.89990234375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1450.pth'\n",
      "Episode: 1460, average reward: 1973.9000244140625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1460.pth'\n",
      "Episode: 1470, average reward: 1484.699951171875\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1470.pth'\n",
      "Episode: 1480, average reward: 1598.300048828125\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1480.pth'\n",
      "Episode: 1490, average reward: 1725.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1490.pth'\n",
      "Episode: 1500, average reward: 1835.800048828125\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1500.pth'\n",
      "Episode: 1510, average reward: 1968.5\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1510.pth'\n",
      "Episode: 1520, average reward: 2252.5\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1520.pth'\n",
      "Episode: 1530, average reward: 2378.300048828125\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1530.pth'\n",
      "Episode: 1540, average reward: 2133.5\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1540.pth'\n",
      "Episode: 1550, average reward: 1935.800048828125\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1550.pth'\n",
      "Episode: 1560, average reward: 2238.5\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1560.pth'\n",
      "Episode: 1570, average reward: 2327.699951171875\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1570.pth'\n",
      "Episode: 1580, average reward: 2011.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1580.pth'\n",
      "Episode: 1590, average reward: 1293.0999755859375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1590.pth'\n",
      "Episode: 1600, average reward: 1134.800048828125\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1600.pth'\n",
      "Episode: 1610, average reward: 971.2000122070312\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1610.pth'\n",
      "Episode: 1620, average reward: 1329.800048828125\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1620.pth'\n",
      "Episode: 1630, average reward: 1477.5999755859375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1630.pth'\n",
      "Episode: 1640, average reward: 1774.5999755859375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1640.pth'\n",
      "Episode: 1650, average reward: 1805.5\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1650.pth'\n",
      "Episode: 1660, average reward: 2040.699951171875\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1660.pth'\n",
      "Episode: 1670, average reward: 1411.5999755859375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1670.pth'\n",
      "Episode: 1680, average reward: 1156.300048828125\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1680.pth'\n",
      "Episode: 1690, average reward: 1703.800048828125\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1690.pth'\n",
      "Episode: 1700, average reward: 1727.800048828125\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1700.pth'\n",
      "Episode: 1710, average reward: 1812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1710.pth'\n",
      "Episode: 1720, average reward: 2505.300048828125\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1720.pth'\n",
      "Episode: 1730, average reward: 2492.89990234375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1730.pth'\n",
      "Episode: 1740, average reward: 2425.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1740.pth'\n",
      "Episode: 1750, average reward: 2376.300048828125\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1750.pth'\n",
      "Episode: 1760, average reward: 2075.89990234375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1760.pth'\n",
      "Episode: 1770, average reward: 1766.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1770.pth'\n",
      "Episode: 1780, average reward: 1459.5\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1780.pth'\n",
      "Episode: 1790, average reward: 2257.199951171875\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1790.pth'\n",
      "Episode: 1800, average reward: 2488.199951171875\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1800.pth'\n",
      "Episode: 1810, average reward: 2103.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1810.pth'\n",
      "Episode: 1820, average reward: 2252.199951171875\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1820.pth'\n",
      "Episode: 1830, average reward: 1618.800048828125\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1830.pth'\n",
      "Episode: 1840, average reward: 1649.300048828125\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1840.pth'\n",
      "Episode: 1850, average reward: 2048.39990234375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1850.pth'\n",
      "Episode: 1860, average reward: 1672.699951171875\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1860.pth'\n",
      "Episode: 1870, average reward: 1182.199951171875\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1870.pth'\n",
      "Episode: 1880, average reward: 1745.0999755859375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1880.pth'\n",
      "Episode: 1890, average reward: 1374.0999755859375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1890.pth'\n",
      "Episode: 1900, average reward: 2046.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1900.pth'\n",
      "Episode: 1910, average reward: 1639.199951171875\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1910.pth'\n",
      "Episode: 1920, average reward: 1944.300048828125\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1920.pth'\n",
      "Episode: 1930, average reward: 1692.199951171875\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1930.pth'\n",
      "Episode: 1940, average reward: 1868.800048828125\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1940.pth'\n",
      "Episode: 1950, average reward: 2270.39990234375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1950.pth'\n",
      "Episode: 1960, average reward: 2061.199951171875\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1960.pth'\n",
      "Episode: 1970, average reward: 2171.60009765625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1970.pth'\n",
      "Episode: 1980, average reward: 2364.300048828125\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1980.pth'\n",
      "Episode: 1990, average reward: 1973.5999755859375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_1990.pth'\n",
      "Episode: 2000, average reward: 2190.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2000.pth'\n",
      "Episode: 2010, average reward: 1984.5\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2010.pth'\n",
      "Episode: 2020, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2020.pth'\n",
      "Episode: 2030, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2030.pth'\n",
      "Episode: 2040, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2040.pth'\n",
      "Episode: 2050, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2050.pth'\n",
      "Episode: 2060, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2060.pth'\n",
      "Episode: 2070, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2070.pth'\n",
      "Episode: 2080, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2080.pth'\n",
      "Episode: 2090, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2090.pth'\n",
      "Episode: 2100, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2100.pth'\n",
      "Episode: 2110, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2110.pth'\n",
      "Episode: 2120, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2120.pth'\n",
      "Episode: 2130, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2130.pth'\n",
      "Episode: 2140, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2140.pth'\n",
      "Episode: 2150, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2150.pth'\n",
      "Episode: 2160, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2160.pth'\n",
      "Episode: 2170, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2170.pth'\n",
      "Episode: 2180, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2180.pth'\n",
      "Episode: 2190, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2190.pth'\n",
      "Episode: 2200, average reward: 856.7999877929688\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2200.pth'\n",
      "Episode: 2210, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2210.pth'\n",
      "Episode: 2220, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2220.pth'\n",
      "Episode: 2230, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2230.pth'\n",
      "Episode: 2240, average reward: 744.7000122070312\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2240.pth'\n",
      "Episode: 2250, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2250.pth'\n",
      "Episode: 2260, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2260.pth'\n",
      "Episode: 2270, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2270.pth'\n",
      "Episode: 2280, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2280.pth'\n",
      "Episode: 2290, average reward: 677.4000244140625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2290.pth'\n",
      "Episode: 2300, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2300.pth'\n",
      "Episode: 2310, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2310.pth'\n",
      "Episode: 2320, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2320.pth'\n",
      "Episode: 2330, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2330.pth'\n",
      "Episode: 2340, average reward: 758.2000122070312\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2340.pth'\n",
      "Episode: 2350, average reward: 724.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2350.pth'\n",
      "Episode: 2360, average reward: 722.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2360.pth'\n",
      "Episode: 2370, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2370.pth'\n",
      "Episode: 2380, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2380.pth'\n",
      "Episode: 2390, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2390.pth'\n",
      "Episode: 2400, average reward: 753.9000244140625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2400.pth'\n",
      "Episode: 2410, average reward: 806.2999877929688\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2410.pth'\n",
      "Episode: 2420, average reward: 793.4000244140625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2420.pth'\n",
      "Episode: 2430, average reward: 753.9000244140625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2430.pth'\n",
      "Episode: 2440, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2440.pth'\n",
      "Episode: 2450, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2450.pth'\n",
      "Episode: 2460, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2460.pth'\n",
      "Episode: 2470, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2470.pth'\n",
      "Episode: 2480, average reward: 768.7999877929688\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2480.pth'\n",
      "Episode: 2490, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2490.pth'\n",
      "Episode: 2500, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2500.pth'\n",
      "Episode: 2510, average reward: 714.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2510.pth'\n",
      "Episode: 2520, average reward: 704.2000122070312\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2520.pth'\n",
      "Episode: 2530, average reward: 811.4000244140625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2530.pth'\n",
      "Episode: 2540, average reward: 793.4000244140625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2540.pth'\n",
      "Episode: 2550, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2550.pth'\n",
      "Episode: 2560, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2560.pth'\n",
      "Episode: 2570, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2570.pth'\n",
      "Episode: 2580, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2580.pth'\n",
      "Episode: 2590, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2590.pth'\n",
      "Episode: 2600, average reward: 811.7999877929688\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2600.pth'\n",
      "Episode: 2610, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2610.pth'\n",
      "Episode: 2620, average reward: 805.7000122070312\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2620.pth'\n",
      "Episode: 2630, average reward: 806.2999877929688\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2630.pth'\n",
      "Episode: 2640, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2640.pth'\n",
      "Episode: 2650, average reward: 811.5999755859375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2650.pth'\n",
      "Episode: 2660, average reward: 809.7000122070312\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2660.pth'\n",
      "Episode: 2670, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2670.pth'\n",
      "Episode: 2680, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2680.pth'\n",
      "Episode: 2690, average reward: 807.7999877929688\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2690.pth'\n",
      "Episode: 2700, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2700.pth'\n",
      "Episode: 2710, average reward: 810.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2710.pth'\n",
      "Episode: 2720, average reward: 735.9000244140625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2720.pth'\n",
      "Episode: 2730, average reward: 699.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2730.pth'\n",
      "Episode: 2740, average reward: 807.9000244140625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2740.pth'\n",
      "Episode: 2750, average reward: 810.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2750.pth'\n",
      "Episode: 2760, average reward: 773.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2760.pth'\n",
      "Episode: 2770, average reward: 808.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2770.pth'\n",
      "Episode: 2780, average reward: 736.2000122070312\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2780.pth'\n",
      "Episode: 2790, average reward: 809.9000244140625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2790.pth'\n",
      "Episode: 2800, average reward: 809.9000244140625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2800.pth'\n",
      "Episode: 2810, average reward: 809.9000244140625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2810.pth'\n",
      "Episode: 2820, average reward: 810.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2820.pth'\n",
      "Episode: 2830, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2830.pth'\n",
      "Episode: 2840, average reward: 812.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2840.pth'\n",
      "Episode: 2850, average reward: 882.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2850.pth'\n",
      "Episode: 2860, average reward: 945.2999877929688\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2860.pth'\n",
      "Episode: 2870, average reward: 910.0999755859375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2870.pth'\n",
      "Episode: 2880, average reward: 984.2000122070312\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2880.pth'\n",
      "Episode: 2890, average reward: 1306.0999755859375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2890.pth'\n",
      "Episode: 2900, average reward: 1346.4000244140625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2900.pth'\n",
      "Episode: 2910, average reward: 1095.699951171875\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2910.pth'\n",
      "Episode: 2920, average reward: 1429.0999755859375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2920.pth'\n",
      "Episode: 2930, average reward: 1176.300048828125\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2930.pth'\n",
      "Episode: 2940, average reward: 1169.800048828125\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2940.pth'\n",
      "Episode: 2950, average reward: 1244.5\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2950.pth'\n",
      "Episode: 2960, average reward: 1452.5\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2960.pth'\n",
      "Episode: 2970, average reward: 1362.0999755859375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2970.pth'\n",
      "Episode: 2980, average reward: 1048.699951171875\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2980.pth'\n",
      "Episode: 2990, average reward: 1689.5\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_2990.pth'\n",
      "Episode: 3000, average reward: 1431.300048828125\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_3000.pth'\n",
      "Episode: 3010, average reward: 1917.199951171875\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_3010.pth'\n",
      "Episode: 3020, average reward: 1663.199951171875\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_3020.pth'\n",
      "Episode: 3030, average reward: 1728.5\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_3030.pth'\n",
      "Episode: 3040, average reward: 1937.5999755859375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_3040.pth'\n",
      "Episode: 3050, average reward: 2329.39990234375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_3050.pth'\n",
      "Episode: 3060, average reward: 1949.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_3060.pth'\n",
      "Episode: 3070, average reward: 2186.10009765625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_3070.pth'\n",
      "Episode: 3080, average reward: 2066.60009765625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_3080.pth'\n",
      "Episode: 3090, average reward: 1836.9000244140625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_3090.pth'\n",
      "Episode: 3100, average reward: 2091.39990234375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_3100.pth'\n",
      "Episode: 3110, average reward: 2300.60009765625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_3110.pth'\n",
      "Episode: 3120, average reward: 1908.699951171875\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_3120.pth'\n",
      "Episode: 3130, average reward: 2203.199951171875\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_3130.pth'\n",
      "Episode: 3140, average reward: 2523.60009765625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_3140.pth'\n",
      "Episode: 3150, average reward: 2168.699951171875\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_3150.pth'\n",
      "Episode: 3160, average reward: 2289.89990234375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_3160.pth'\n",
      "Episode: 3170, average reward: 2230.300048828125\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_3170.pth'\n",
      "Episode: 3180, average reward: 1939.4000244140625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_3180.pth'\n",
      "Episode: 3190, average reward: 2197.199951171875\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_3190.pth'\n",
      "Episode: 3200, average reward: 1987.4000244140625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_3200.pth'\n",
      "Episode: 3210, average reward: 1484.9000244140625\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_3210.pth'\n",
      "Episode: 3220, average reward: 1846.699951171875\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_3220.pth'\n",
      "Episode: 3230, average reward: 1816.5\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_3230.pth'\n",
      "Episode: 3240, average reward: 1257.5\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_3240.pth'\n",
      "Episode: 3250, average reward: 1939.800048828125\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_3250.pth'\n",
      "Episode: 3260, average reward: 2410.5\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_3260.pth'\n",
      "Episode: 3270, average reward: 1915.0\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_3270.pth'\n",
      "Episode: 3280, average reward: 2597.5\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_3280.pth'\n",
      "Episode: 3290, average reward: 2951.39990234375\n",
      "Checkpoint saved to 'C:\\Users\\Computing\\Desktop\\PPO seed 128 without baseline\\checkpoint_3290.pth'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-0093ac6b592a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msolver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPPOSolver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0msolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-c1f950562baa>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, samples, clip_range)\u001b[0m\n\u001b[0;32m     97\u001b[0m                 \u001b[0mmini_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmini_batch_indexes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalculate_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclip_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclip_range\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmini_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-c1f950562baa>\u001b[0m in \u001b[0;36mcalculate_loss\u001b[1;34m(self, samples, clip_range)\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[0msampled_advantages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'advantages'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[0mpi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'obs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[0mratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'actions'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'log_pis'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m         \u001b[0mclipped_ratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mratio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mclip_range\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mclip_range\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0mpolicy_reward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratio\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msampled_advantages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclipped_ratio\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msampled_advantages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\distributions\\categorical.py\u001b[0m in \u001b[0;36mlog_prob\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_pmf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\distributions\\distribution.py\u001b[0m in \u001b[0;36m_validate_sample\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    274\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0msupport\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msupport\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'The value argument must be within the support'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "solver = PPOSolver()\n",
    "while True:\n",
    "    solver.train(solver.sample(), 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103e052d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20438c79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
